---
title: "Green Book Section I.C.1.a: Determining Measurability"
subtitle: "BOX I.C.I.a.ii. Transects for monitoring vegetation response to pumping"
author: "Water Department - County of Inyo"
date: "7/8/2021"
output: 
 html_document: 
   code_folding: hide
   fig_caption: yes
   toc: yes
   toc_depth: 5
   toc_float:
     collapsed: no
     smooth_scroll: yes
editor_options: 
  chunk_output_type: inline
---


  

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
library(targets)
library(tidyverse)
library(rmarkdown)
library(DT)
library(htmlwidgets)
library(sf)
library(tmap)
library(tmaptools)
library(here)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(tidyverse.quiet = TRUE)
```

# Introduction {.tabset}
```{r tar-load-initial}
tar_load(n_parcels_sampled)
tar_load(cYear)
tar_load(n_transects_sampled)
```

## Purpose
Inyo County Water Department monitors trends in vegetation cover and species composition in groundwater-dependent vegetation parcels following protocols described in the Technical appendix to the Water Agreement (Green Book Box I.C.1.a.ii, [revised 2017](https://www.inyowater.org/wp-content/uploads/2017/09/GBMemo_SCfeb2017.pdf)). The primary purpose of this monitoring is to detect any “Significant decreases and changes in Owens Valley vegetation from conditions documented in 1984 to 1987". Vegetation management goals of the Agreement are based on canopy cover and species composition recorded during LADWP’s 1984-87 baseline vegetation parcel mapping and vegetation sampling effort.  To evaluate the condition of the vegetation, field crews of ICWD and LADWP monitor vegetation at permanent locations within a subset of the groundwater-dependent parcels potentially affected by pumping.

The purpose of this report is to provide the Inyo-LA Technical Group with an annual summary of the groundwater-dependent vegetation parcels on LA-owned land that show measurably different vegetation characteristics from the 1984-87 vegetation baseline. 

Green Book Box I.C.1.a.ii., "Transects for monitoring vegetation response to pumping", was revised by the Technical Group and Standing Committee in 2017 to reflect agreement on jointly managing the vegetation monitoring program and statistical procedures for annually determining whether estimated levels of vegetation change are compatible with Agreement goals.  This report provides this measurability analysis.



## Green Book Box I.C.1.a.ii{data-short-title="Green Book Methods"}

[**TRANSECTS FOR MONITORING VEGETATION RESPONSE TO PUMPING**](https://www.inyowater.org/wp-content/uploads/2017/09/GBMemo_SCfeb2017.pdf)

Vegetation transects are included within the Green Book to serve two purposes: 1) to estimate transpiration from a monitoring site, and 2) for use in determining whether vegetation has decreased or changed significantly from the previous cover. 

1) Detailed measurements of leaf area index shall be made at each of the monitoring sites using the techniques described in Section III.C. These measurements will be used to estimate evapotranspiration from the vegetation at the monitoring site for comparison to available soil water and, ultimately, to project plant-soil water balance and the need for water table recovery. Vegetation transects shall also be used in cases of suspected vegetation changes due to groundwater pumping. However, rather than using the intensive sampling technique of Section III.D for calculating evapotranspiration, plant cover shall be measured by the line-point technique described below.
 
2) During the 1984-87 inventory, most parcels were sampled with line-point transects of 100 feet in length, with sampling points at one-foot intervals, providing a two-dimensional representation of vegetation within the parcel. At each one-foot marker, the first contact with the uppermost layer of live plant cover was recorded. Cover and species composition were calculated from all sampling points along the transect.

The 1984-87 inventory shall be used as a "baseline" to determine whether vegetation cover and/or species composition has changed. This inventory is the only one of sufficient accuracy to permit comparison of species composition and cover.

A subset of the vegetation parcels mapped during the 1984-87 baseline inventory shall be annually monitored to accommodate statistical comparison with data collected during the baseline inventory. Such monitoring may rely on repeat measurement of georeferenced locations using the line-point-intercept method to track live cover and species composition over time. The baseline inventory was summarized at the parcel scale, thus for statistical comparison, transect locations derived from a set of random locations and azimuths provide a valid statistical comparison. 

Parcels to be monitored were initially selected based on meeting one or more of the following criteria: (1) parcel contained a permanent monitoring site; (2) baseline inventory data were collected for the parcel; (3) parcel was in close proximity to a pumping well; (4) information of past and current land use for parcel was available; (5) parcel was representative of one of the groundwater-dependent plant communities originally mapped during the baseline inventory; (6) soil characterization was available for the parcel; (7) characterization of the landscape position was available for the parcel. In 2015, Inyo County and Los Angeles began a joint monitoring program utilizing a combination of parcels and transects evaluated and agreed upon by the staffs of both parties. As of 2016, 1,688 transects across 141 parcels are jointly monitored by both parties.   

Approximately 100 of the 141 parcels monitored in 2016 will be jointly selected and monitored each year by Inyo County and Los Angeles. Prior to the field season, staff from both parties will determine which parcels of the 141 will be monitored. Existing permanent transects will be used for those parcels selected unless the staffs of both parties agree that a change in transect location is justified and necessary. Transects will be evenly split between ICWD and LADWP. Either party may independently conduct monitoring of additional parcels or transects; however, any data so collected shall be provided to the other party. 

The field protocol and calibration for field observations for the joint line-point monitoring program largely follows Herrick et al.(2016). At the onset of the monitoring season, staff from both parties shall meet in the field to discuss methods and to calibrate all field personnel.  In summary the field protocol is as follows: 

1. navigate to the transect start point with a handheld GPS device; 
2. verify presence of an aluminum tag which has been previously attached to a nearby object (i.e. shrub, debris, etc.); 
3. use a photo taken from the previous year to precisely locate the transect start point and to examine the accuracy of the azimuth used during the previous year; 
4. if the start point on the photo is off by more than 6 meters from the point indicated by a GPS reading, or a start point cannot be positively identified, a start point will be placed at the point indicated by the GPS device;
5. if the designated transect azimuth is off by more than ±5 degrees from the azimuth depicted within the previous year’s transect photo, the designated transect azimuth will be used. If not, the azimuth depicted within the previous year’s photo will be upheld;
6. stretch a tape measure to the direction of the pre-established azimuth;
7. for each transect, notes shall be taken on whether an aluminum tag is present, and whether or not the current year’s start point and compass azimuth matches those depicted within the previous year’s transect photo; 
8. record species identity at each half meter starting at 0.5 m and ending at 50 m yielding 100 possible hits; 
9. place a dry erase board with the parcel name, transect number, azimuth and date at the base on the transect line and take a picture from the start point toward the end point that captures the entire transect.

All live cover is tallied for each species for each transect. Data are exchanged at the end of the field season after each party digitally enters and proofs field data. 

The field technique and sampling design may be modified to permit detailed statistical comparison if deemed necessary in the future. Statistical analysis will be used to determine the measurability (statistical significance) of vegetation changes from the 1984-87 baseline inventory maps. Such an analysis may include, but is not limited to, Welch’s test (t-test with unequal variance), Wilcox test (Mann-Whitney test), Analysis of Variance (ANOVA) and Generalized Linear Model (GLM) for vegetation cover and permutational Multivariate Analysis of Variance (PERMANOVA) and Nonmetric Multidimensional Scaling (NMDS) for vegetation composition. For parcels with small baseline inventory sample sizes (e.g. 1-4 transects), a one-sample t-test may be performed using the baseline inventory sample mean as the null hypothesis for the test. Determination of measurability will be made by the Technical Group on case by case basis in accordance with Water Agreement IV.B and Green Book Section I.C.

Box I.C.1.a.ii shall be modified as necessary in the future to incorporate new or modified field techniques, technology, and/or analytical methods.  Such changes will be jointly developed by the staffs from both Inyo County and Los Angeles and will be presented to the Technical Group for consideration.


# Methods{.tabset}

## Baseline
From September 1984 to Nov 1987, LADWP inventoried and mapped vegetation into 2126 polygons of similar vegetation type, ‘vegetation parcels’ (223,168 acres).  Most of these lands were characterized as nonphreatophytic plant communities (Green Book management type A). The Green Book vegetation monitoring program is focused on groundwater-dependent parcels (Green Book types B, C, D and some E) and primarily those potentially affected by groundwater pumping. 

 
## Parcel Selection
Parcels were initially selected based on meeting one or more of the following criteria: (1) the parcel contained a permanent monitoring site where soil/vegetation water balance is calculated; (2) baseline data was collected for the parcel; (3) the parcel was in close proximity to a pumping well; (4) information of past and current land use for the parcel was available.  

## Control Wellfield Designation
Parcels were classified as either belonging to a wellfield group or control group based on criteria derived from groundwater drawdown during the period of maximum pumping rate that occurred between 1987 and 1993. Parcels were assigned to the wellfield group if (1) kriged DTW estimates exceeded 1-m water-table drawdown during 1987-1993 or (2) they were located at sites corresponding to modeled drawdown contours greater than 10 ft. Parcels were assigned to the control group if (1) kriged DTW estimates were less than 1 m and (2) they were located at sites corresponding to modeled drawdown contours less than 10 ft. If the kriged DTW estimates were not reliable owing an inadequate test-well network near the vegetation parcel, then the groundwater-flow model estimate of the 10-ft drawdown contour was used as the sole criteria to designate parcels as either wellfield or control. An exception to the above criteria was applied to parcels associated with drawdown contours greater than 10-ft yet located near a surface water source (specifically, a canal, sewer pond, creek, river, or a ground water seepage source) that would lessen local drawdown effects—these parcels were classified as control. Some parcels currently in the wellfield group have higher water tables than during the 1987 to 1993 period, but remain in the wellfield group because of their close proximity to pumping wells and potential for pumping-induced drawdown.  Each parcel is also classified by its Green Book management type, Holland plant community type and by its status as either wellfield or control.

## Sample size
Most parcels were sampled in 1984-1987 using line-point-intercept sampling. Some parcels were not directly sampled but rather assigned cover and composition values from parcels with similar vegetation conditions. Welch’s t-test for unequal variance was used to evaluate in which parcels and in which year(s) total perennial cover and perennial grass cover has significantly differed from baseline. Since the sample standard deviation is used to construct 95% confidence interval, this method can be used for parcels in which baseline data contained more than one transect or nonzero sample variance. Where unmeasured parcels during baseline subsequently inherited a single baseline value from nearby parcels, a one-sample t-test is used to determine significance from baseline. For parcels with low baseline sample sizes, procedures in Green Book Box I.C.1.a.ii were followed: "For parcels with small baseline inventory sample sizes (e.g. 1-4 transects), a one-sample t-test may be performed using the baseline inventory sample mean as the null hypothesis for the test".

## Data

**Field Data (line-point-intercept)**

The number of parcels sampled each year as well as the number of transects sampled per parcel has varied due to fluctuations in annual staffing.  Thus, some parcels have varying numbers of transects sampled across time.  Other parcels have not been sampled continuously during the entire monitoring period. In `r cYear`, `r n_parcels_sampled` were sampled.

Perennial species cover is considered in this report, because annual species are not dependent on groundwater.  Perennial cover was further aggregated into grass, non-gramminoid herbaceous (herb), and shrub.  In order to analyze the changes in the composition of total perennial cover, the proportion of shrub, herb and grass cover as a fraction of total perennial cover was calculated. Transect data are summarized for each parcel and year using the arithmetic average, creating a history of cover over time for each parcel.  

**Remote Sensing**

Normalized difference vegetation index (NDVI) derived from Landsat 5/7/8 was extracted from google earth engine using the python API and an open source toolbox [ee-tools](https://github.com/Map-Water/ee-tools). Pixels were zonally averaged to the parcel polygons over July 15-Sep 15, creating a full history of remotely-sensed vegetation change starting during the baseline period in 1985. The Landsat dataset is produced by NASA/USGS, and the Landsat Science Team does the processing (masking clouds, preparing best images for 8-day,16-day images) before it is archived to the dataset on Google Earth Engine.  

**Precipitation**

Precipitation dataset was acquired using the gridMET/METDATA dataset produced at the University of Idaho and provided by MapWater consultants. It is a daily dataset of historically observed meteorological variables from Jan 1, 1979 to 2-days lag from the current date. It is produced over the contiguous United States (CONUS). GridMet is produced by bias correcting the daily NLDAS2 dataset to monthly PRISM values producing values on a 4-km (1/24-deg) grid (climateengine.org). 

## `targets`
The `Targets` R package is a data pipeline toolkit allowing dependency awareness and automatic rerunning of code that is downstream from dependency changes. A single `_targets.R` script was constructed specifying which datasets are input into which functions, and which outputs are then input into further downstream functions. The functions to process and analyze the data are maintained in a single file from `code/R/functions.R` and the `_targets.R` script sources these functions to make the pipeline.

The targets package `tar_visnetwork()` function output shows the data pipeline in an interactive format. Links are dependencies between functions and targets (input files, intermediate data transformations, model objects, plots and tables etc) specifying which targets are upstream from others and which are out of date. Functions are shown as triangles and targets are shown as circles. Fill color indicates whether or not upstream dependencies are 'Up to date' (green) or 'Outdated' (blue). Only the downstream dependencies of outdated targets or functions will be re-evaluated when the pipeline is rerun using `tar_make()`.


```{r visnetwork}
tar_visnetwork()
```

This is the content of the `_targets.R` script file.
```{r targets-show,eval=FALSE}

library(targets)
library(tidyverse)
library(tarchetypes)
library(DT)
library(here)
library(sf)
library(tmaptools)
library(tmap)

source("code/R/functions.R")
tar_option_set(
  packages = c(
    "tidyverse",
    "stringr"
  )
  # debug = fiverow_ts,
  # cue = tar_cue(mode = "never"),
)
list(
  tar_target(cYear, 2020),
# GIS
  tar_target(parcels_shp_file, "data/gisdata/LA_parcels_rasterizedd.shp", format = 'file'),
  tar_target(parcels_shp, st_read(parcels_shp_file)),

  tar_target(canals_shp_file, "data/gisdata/canals.shp", format = 'file'),
  tar_target(canals_shp, st_read(canals_shp_file, quiet = TRUE)),

  tar_target(monsites_shp_file, "data/gisdata/monsites_icwd_gps.shp", format = 'file'),
  tar_target(monsites_shp, st_read(monsites_shp_file, quiet = TRUE) %>% filter(!is.na(SITENAME))),

  tar_target(or_shp_file, "data/gisdata/OwensRiver.shp", format = 'file'),
  tar_target(or_shp, st_read(or_shp_file, quiet = TRUE)),

  tar_target(laa_shp_file, "data/gisdata/LA_aqueduct_nad83.shp", format = 'file'),
  tar_target(laa_shp, st_read(laa_shp_file, quiet = TRUE)),

  tar_target(lakes_shp_file, "data/gisdata/lakes.shp", format = 'file'),
  tar_target(lakes_shp, st_read(lakes_shp_file, quiet = TRUE)),

  tar_target(streams_shp_file, "data/gisdata/streams.shp", format = 'file'),
  tar_target(streams_shp, st_read(streams_shp_file, quiet = TRUE)),


  tar_target(species_file, "data/species.csv", format = "file"),
  tar_target(species, read.csv(species_file)),


  tar_target(icwd_file,"data/lpt_ICWD.csv", format = "file"),
  tar_target(icwd_wide, read.csv(icwd_file)),
  tar_target(icwd_long, pivot_longer_icwd(icwd_wide)),
  tar_target(icwd_processed,
             add_species_agency_plotid(long = icwd_long,cYear,species, entity = "ICWD")),
  tar_target(icwd_output_csv, save_csv_and_return_path(processed = icwd_processed,cYear,entity = "ICWD"),
    format = "file"),

  tar_target(ladwp_file, "data/lpt_LADWP.csv", format = "file"),
  tar_target(ladwp_long, read.csv(ladwp_file)),
  tar_target(ladwp_processed,
              add_species_agency_plotid(long = ladwp_long,cYear,species, entity = "LADWP")),

  tar_target(ladwp_output_csv, save_csv_and_return_path(processed = ladwp_processed,cYear,entity = "LADWP"),
             format = "file"),
  tar_target(icwd_ladwp_bind, bind_rows(icwd_processed, ladwp_processed)),

  tar_target(icwd_ladwp_output_csv, save_csv_and_return_path(processed = icwd_ladwp_bind,cYear,entity = "ICWD_LADWP_merged"),
             format = "file"),

  tar_target(lpt_prev_master_file, "data/lpt_MASTER.csv", format = "file"),
  tar_target(lpt_prev_master, read.csv(lpt_prev_master_file)),

  tar_target(lpt_updated_master, bind_rows(icwd_ladwp_bind, lpt_prev_master)),
  tar_target(n_parcels_all_years, count_parcels_all_years(lpt_updated_master)),
  tar_target(n_parcels_sampled, count_parcels_cyear(n_parcels_all_years, cYear)),
tar_target(n_transects_sampled, count_transects_cyear(lpt_updated_master,cYear)),
  tar_target(lpt_updated_master_csv, save_csv_and_return_path(processed = lpt_updated_master,cYear,entity = "MASTER"),
             format = "file"),

  tar_target(lpt_long_no_lela, filt_lela(data = lpt_updated_master)),
  tar_target(lpt_long_no_lela_pfix, mult_to_single_parcel_name(x = lpt_long_no_lela)),
  tar_target(long_combined_nl_csv, save_csv_and_return_path(processed = lpt_long_no_lela_pfix,cYear,entity = "long_combined_nl"),
             format = "file"),

  tar_target(wvcom_file, "data/wvcom1.csv", format = "file"),
  tar_target(wvcom, read.csv(wvcom_file)),
  tar_target(wvcom_pfix, mult_to_single_parcel_name(x = wvcom)),

  tar_target(transects, summarise_to_transect(x=lpt_long_no_lela_pfix, y=wvcom_pfix)),
  tar_target(parcels, summarise_to_parcel(x= transects)),
  tar_target(parcels_deltas, add_parcel_deltas(parcels)),

  tar_target(rs_file, "data/rs.csv", format = "file"),
  tar_target(rs, read.csv(rs_file)),
  tar_target(rs_pfix, mult_to_single_parcel_name(x = rs)),

  tar_target(attributes_file, "data/Attributes.csv", format = "file"),
  tar_target(attributes, read.csv(attributes_file)),
  tar_target(attributes_pfix, mult_to_single_parcel_name(x = attributes)),
  tar_target(attributes_reinv, filter(attributes_pfix,reinv == "r")),

  tar_target(wellcont_means, wellfield_control_means(parcels_deltas, attributes_pfix)),
  tar_target(wellcont_means_rarefied, wellfield_control_means_rarefied(parcels_deltas, attributes_pfix)),
  tar_target(plot_wellcontrol, plot_wellfield_control(wellcont_means_rarefied)),

  tar_target(dtw_file, "data/dtw.csv", format = "file"),
  tar_target(dtw, read.csv(dtw_file)),
  tar_target(dtw_pfix, mult_to_single_parcel_name(x = dtw)),

  tar_target(parcel_year_meta, nest_transects(transects, attributes_reinv)),
  tar_target(parcel_year_meta_2samp,filter(parcel_year_meta, n.y > 4) ),
  tar_target(parcel_year_meta_1samp, filter(parcel_year_meta, n.y <= 4)),

  tar_target(parcel_year_meta_2samp_results, two_sample_ttest(parcel_year_meta_2samp)),
  tar_target(parcel_year_meta_1samp_results, one_sample_ttest(parcel_year_meta_1samp)),
  tar_target(parcel_year_meta_combined_results, bind_rows(parcel_year_meta_2samp_results,parcel_year_meta_1samp_results)),

  tar_target(parcel_select_1sample, c("IND026")),
  tar_target(parcel_select_2sample, c("BLK094")),
  tar_target(plot_2sample_timeseries, plot_2samptest_timeseries(parcel_year_meta_2samp_results,cYear,parcel_select_2sample)),
  tar_target(plot_1sample_timeseries, plot_1samptest_timeseries(parcel_year_meta_1samp_results,cYear,parcel_select_1sample)),

  tar_target(deltas_ttest_att, join_summaries(parcels_deltas,attributes_pfix, parcel_year_meta_combined_results, cYear)),

  tar_target(parcel_datatable, parcel_data_table(deltas_ttest_att,cYear)),
  # Join GIS parcels to sig tests
  tar_target(parcels_shp_ttest, left_join(parcels_shp, deltas_ttest_att, by = c("PCL"="Parcel"))),
  # create map of sig tests

  # for static plots iterating over many areas, dynamic branching?
  tar_target(panel_map_lw, panel_map(cYear, parcels_shp_ttest, "Laws", or_shp,streams_shp,canals_shp,laa_shp,lakes_shp, monsites_shp)),
  tar_target(panel_map_bp, panel_map(cYear, parcels_shp_ttest, "Big Pine", or_shp,streams_shp,canals_shp,laa_shp,lakes_shp, monsites_shp)),
  tar_target(panel_map_ta, panel_map(cYear, parcels_shp_ttest, "Taboose-Aberdeen", or_shp,streams_shp,canals_shp,laa_shp,lakes_shp, monsites_shp)),
  tar_target(panel_map_ts, panel_map(cYear, parcels_shp_ttest, "Thibaut-Sawmill", or_shp,streams_shp,canals_shp,laa_shp,lakes_shp, monsites_shp)),
  tar_target(panel_map_io, panel_map(cYear, parcels_shp_ttest, "Independence-Oak", or_shp,streams_shp,canals_shp,laa_shp,lakes_shp, monsites_shp)),
  tar_target(panel_map_ss, panel_map(cYear, parcels_shp_ttest, "Symmes-Shepherd", or_shp,streams_shp,canals_shp,laa_shp,lakes_shp, monsites_shp)),
  tar_target(panel_map_bg, panel_map(cYear, parcels_shp_ttest, "Bairs-George", or_shp,streams_shp,canals_shp,laa_shp,lakes_shp, monsites_shp))
# ,
  # tar_target(panel_map_lp, panel_map(cYear, parcels_shp_ttest, "Lone Pine", or_shp,streams_shp,canals_shp,laa_shp,lakes_shp, monsites_shp))



 # tar_render(report, "report.Rmd")
  )

  # tar_target(fiverow_ts, five_row_timeseries(attributes_pfix, transects, dtw_pfix, rs_pfix, cYear))
```

This is the content of the `functions.R`
```{r show-functions,eval=FALSE}

#' Title
#'
#' @param icwd_wide
#'
#' @return
#' @export
#'
#' @examples
pivot_longer_icwd <- function(icwd_wide){
  icwd_wide %>%
    gather(Transect, Cover, T1:T24) %>%
    filter(!is.na(Cover))%>%
    mutate(Transect = str_replace(Transect, "\\T",""),
           Transect = as.numeric(Transect))

# now that the data is in long format, filter out the NAs associated with 'trace species' and rows with zero hits which is a byproduct of having the data in wide format.
# zero transects prevent this from being adequate
}

# add attributes for simple output - annual data transfer to LADWP
#' Title
#'
#' @param long
#' @param cYear
#' @param species
#' @param entity
#'
#' @return
#' @export
#'
#' @examples
add_species_agency_plotid <- function(long,cYear,species,entity){
  long %>% left_join(species, by = "Code")%>%
    mutate(source = 'Joint Monitoring 2015-current year',
           source.abr = 'jm',
           Year = cYear,
           Entity = entity,
           plotid = paste(Parcel,Transect,source.abr,sep = '_'),
           plotid.full = paste(Parcel,Transect,source.abr,Entity,sep = '_'))%>%
    select(Parcel, Code, Transect, Cover, Year, Entity, plotid, Species, CommonName, Order, Family, Genus, Lifecycle, Lifeform, Veg_Type, source, source.abr, Phreatophyte, plotid.full) %>%
    arrange(Parcel, Transect, Code)
}

#
#' Title
#'
#' @param processed
#' @param cYear
#' @param entity
#'
#' @return
#' @export
#'
#' @examples
save_csv_and_return_path <- function(processed, cYear, entity) {
  processed %>% write_csv(paste0("output/",entity,"_lpt_",cYear,".csv"))
  return(paste0("output/",entity, "_lpt_",cYear,".csv"))
}

count_parcels_all_years <- function(lpt_updated_master){
  lpt_updated_master %>%
    group_by(Year) %>%
    summarise(n = n_distinct(Parcel))
}

count_parcels_cyear <- function(n_parcels_all_years,cYear){
  n_parcels_sampled_cYear <- n_parcels_all_years %>%
    filter(Year == cYear)
  n_parcels_sampled <- n_parcels_sampled_cYear$n

  return(n_parcels_sampled)
}

count_transects_cyear <- function(lpt_updated_master,cYear){
  cyr_transects <- lpt_updated_master %>% filter(Year == cYear)%>%
    summarise(n = n_distinct(plotid))

  n_transects <- cyr_transects$n
  return(n_transects)
}



# filter out invasive species LELA2 for transect summaries.
#' Title
#'
#' @param data
#'
#' @return
#' @export
#'
#' @examples
filt_lela <- function(data){
  data %>% filter(Species != "LELA2",Species !="LELA")#
}

# revert to single parcels name
#' Title
#'
#' @param x
#'
#' @return
#' @export
#'
#' @examples
mult_to_single_parcel_name <- function(x){
  x$Parcel[x$Parcel=="TIN028_FSP022_FSP019"]<-"TIN028"
  x$Parcel[x$Parcel=="TIN028_FSP019_FSP022"]<-"TIN028"
  x$Parcel[x$Parcel=="MAN006_IND229"]<-"MAN006"
  x$Parcel[x$Parcel=="LAW137_PLC210"]<-"LAW137"
  x$Parcel[x$Parcel=="LAW108_FSL047"]<-"LAW108"
  x$Parcel[x$Parcel=="LAW109_FSL048"]<-"FSL048"
  x$Parcel[x$Parcel=="IND163_BEE017"]<-"IND163"
  x$Parcel[x$Parcel=="IND139_MAN005"]<-"IND139"
  x$Parcel[x$Parcel=="IND024_BLK103"]<-"IND024"
  x$Parcel[x$Parcel=="FSP004_BGP188"]<-"FSP004"
  x$Parcel[x$Parcel=="FSP006_BGP182"]<-"FSP006"
  x$Parcel[x$Parcel=="ABD012_BLK029"]<-"ABD012"
  x$Parcel[x$Parcel=="BLK002_TIN061"]<-"BLK002"
  x$Parcel[x$Parcel=="TIN061_BLK002"]<-"BLK002"
  x$Parcel[x$Parcel=="BIS055_FSL214"]<-"BIS055"
return(x)
}

# summarise cover types to transect, add wvcom values for some transects
#' Title
#'
#' @param x
#' @param y
#'
#' @return
#' @export
#'
#' @examples
summarise_to_transect <- function(x, y){
  tran.sums <- x %>% group_by(Parcel,Year,Transect,source.abr,plotid,Lifecycle,Lifeform)%>%
    summarise(Cover=sum(Cover))# summarise for each e.g. lifecycle/lifeform annual/perennial grass

  tran.tlc <- tran.sums %>%
    group_by(Parcel,Year,plotid) %>% # sum all cover across all lifecycle/lifeform
    summarise(tot.live.cover = sum(Cover))

  pft.wide<-tran.sums %>% spread(Lifeform,Cover)
  pft.wide[is.na(pft.wide)] <- 0

  # create total cover variable
  pft.wide <- pft.wide%>%
    mutate(Cover= Grass + Herb + Shrub + Herb_Shrub + Tree,
           Shrub = Shrub + Herb_Shrub + Tree)

  pft.wide.wtot.cov <- pft.wide %>% filter(Lifecycle=="Perennial")%>%
    left_join(tran.tlc, by = c("Parcel","Year","plotid"))

  bind_add_proportion <- bind_rows(pft.wide.wtot.cov, y) %>%
    mutate(pShrubTran = Shrub / Cover,
           pGrassTran = Grass / Cover,
           pHerbTran = Herb / Cover) %>%
    mutate_if(is.numeric, ~replace_na(., 0))

  return(bind_add_proportion)
}

# summarise from transects to parcels
#' Title
#'
#' @param x
#'
#' @return
#' @export
#'
#' @examples
summarise_to_parcel <- function(x){
  p <- x %>% group_by(Parcel,Year)%>% summarise(
    PerHits=sum(Cover),
    ShrubHits=sum(Shrub),
    HerbHits=sum(Herb),
    GrassHits=sum(Grass),
    Cover=mean(Cover),
    Shrub=mean(Shrub),
    Herb=mean(Herb),
    Grass=mean(Grass),
    TLC=mean(tot.live.cover),

    pShrub=mean(pShrubTran),
    pGrass=mean(pGrassTran),
    pHerb=mean(pHerbTran),
    n.transects = n()) %>%
    mutate(NominalYear = case_when(Year %in% c(1985, 1986, 1987) ~ 1986,
                                   !Year %in% c(1985, 1986, 1987) ~ Year))

return(p)
}


# add deltas baseline to each year
#' Title
#'
#' @param parcels
#'
#' @return
#' @export
#'
#' @examples
add_parcel_deltas <- function(parcels){

  p <- parcels
  for (PID in unique(p$Parcel)) {
  #defines baselineRow variable as parcels with Nominal year as 1986
  baselineRow <- p[p$Parcel==PID & p$NominalYear==1986, ]

  #dim() function gets or sets the dimension of a matrix, array or data frame.
  #so the dim function asks if the baselineRow for the current parcel in the loop
  #has been updated with the baseline year. If it hasn't
  if (dim(baselineRow)[1]==0) next


  otherYears <- (p$Parcel==PID & !(p$NominalYear==1986))

  # calculate deltas by subtracting baseline cover from each of
  # other rows, leaving negative values indicating declines from baseline
  p$Cover.Delta[otherYears] <-
    p$Cover[otherYears] - baselineRow$Cover

  p$Shrub.Delta[otherYears] <-
    p$Shrub[otherYears] - baselineRow$Shrub

  p$Herb.Delta[otherYears] <-
    p$Herb[otherYears] - baselineRow$Herb

  p$Grass.Delta[otherYears] <-
    p$Grass[otherYears] - baselineRow$Grass
  }
  return(p)
}

#' Title
#'
#' @param parcels_deltas
#' @param attributes
#'
#' @return
#' @export
#'
#' @examples
wellfield_control_means <- function(parcels_deltas, attributes){

  Parcels <- attributes %>% select(Parcel, Type) %>% left_join(parcels_deltas, by = "Parcel")

  Parcels %>% group_by(Type, NominalYear) %>%
    dplyr::summarize(
      count=n(),
      Cover=mean(Cover),
      Grass=mean(Grass),
      Herb=mean(Herb),
      Shrub=mean(Shrub)
      )
}

wellfield_control_means_rarefied <- function(parcels_deltas, attributes){

  Parcels <- attributes %>% select(Parcel, Type) %>% left_join(parcels_deltas, by = "Parcel")

  Parcels %>% filter(Parcel %in% c(
    'BGP031',
    'BLK115',
    'FSL187',
    'IND096',
    'IND163',
    'LNP018',
    'MAN060',
    'PLC024',
    'PLC106',
    'PLC121',
    'PLC223',
    'UNW029',
    'UNW039',
    'BGP154',
    'BGP162',
    'BLK009',
    'BLK016',
    'BLK024',
    'BLK033',
    'BLK039',
    'BLK044',
    'BLK069',
    'BLK074',
    'BLK075',
    'BLK094',
    'BLK099',
    'IND011',
    'IND035',
    'IND106',
    'IND111',
    'IND132',
    'IND139',
    'IND231',
    'LAW063',
    'LAW065',
    'LAW085',
    'LAW107',
    'LAW120',
    'LAW122',
    'MAN006',
    'MAN007',
    'MAN037',
    'TIN028',
    'TIN068')) %>% group_by(Type, NominalYear) %>%
    dplyr::summarize(
      count=n(),
      Cover=mean(Cover),
      Grass=mean(Grass),
      Herb=mean(Herb),
      Shrub=mean(Shrub)
    )
}


plot_wellfield_control <- function(wellcont_means_rarefied){
  plot <-
    wellcont_means_rarefied %>%
    select(-Herb) %>%
    pivot_longer(Cover:Shrub, names_to = "type", values_to = "cover") %>%
    ggplot(aes(x = NominalYear, y = cover, color = Type))+
    geom_point()+
    geom_line()+
    facet_wrap(~type, ncol = 2)

 # ggsave("wellfield_control_rarefied.png", plot, width = 7, height = 7)
  # return("wellfield_control_rarefied.png")
  return(plot)
}

#' Title
#'
#' @param dtw
#'
#' @return
#' @export
#'
#' @examples
#' # this functino per parcel -  needs to be embedded into loop

plot.dtw <- function(PID) {

  # Extract the parcel of interest.

  pcldtw <- dtw %>% filter(Parcel == PID) %>% arrange(Year)
  pcldtw <- pcldtw %>% mutate(phreatic.zone = MIN - 3)
  n <- dim(pcldtw)[1]

  # Find the maximum value that DTW attained over the time span to
  # be plotted.  Allow for missing data.  Set up the plot limits.
  # specifying the max first, then min in ylim sets up the reverse scale we want for DTW plotting where 0 is at top or soil surface representation.

  if(is.na(pcldtw$DTW))
  {ylim<-c(9,0)
  }else{
    this.max.DTW <- max(pcldtw$DTW, na.rm=TRUE) + 1
    # this.min.DTW <- 0)
    ylim <- c(this.max.DTW,0)
  }


  plot(xlim, ylim, xlab='', ylab='DTW [ft]', xlim=xlim, ylim=ylim, yaxs='i', type='n', axes=F)  # Draw solid lines at important depth points.

  # could control ylim in global chunk but if so, need to change above plot function and below axis setup
  # add the axes and a frame.
  axis(side=1, at=seq(xlim[1], xlim[2]), labels=FALSE, tcl=-0.2)
  axis(side=1, at=pretty(xlim))
  axis(side=2, at=pretty(ylim), las=2)
  abline(h=pretty(ylim), col="lightgray")
  box()

  abline(h=6, lwd=1, col="green")
  #text(rmarg, 2, 'Grass root zone', adj=0, xpd=NA)

  abline(h=12, lwd=1, col="brown")
  #text(rmarg, 4, 'Shrub root zone', adj=0, xpd=NA)

  #abline(h=Parcel$DTW[1], lwd=1, col='blue')
  #text(rmarg, Parcel$DTW[1], '1985 DTW', adj=0, xpd=NA)


  # Assess reliability and present data only in cases where
  # the data are reliable or relative recovery reliable.
  # if (as.character(Attribute$DTW.Reliability) %in% c('Reliable', 'Relative Recovery Reliable' , 'Baseline Not Reliable', 'Current DTW Not Reliable','Current DTW Reliable','Need hydrograph Evaluation','NoData','Not Reliable','Baseline Reliable','Validation Needed)) {

  # Draw in a lines and points graph.
  lines(pcldtw$Year, pcldtw$DTW, type='b', pch=16, col="purple")
  #lines(Parcel$Year, Parcel$DTWcap1, type='l', pch=16, col="lightblue")
  # lines(pcldtw$Year, pcldtw$MIN, type='b', pch=16, col="darkblue")
  # lines(pcldtw$Year, pcldtw$MAX, type='b', pch=16, col="grey")
  # lines(pcldtw$Year, pcldtw$phreatic.zone, type='b', pch=16, col="blue")
  # } else {
  #   # Draw nothing.
  # }
  # Indicate the DTW reliability.
  # text(
  #   xlim[1] + (xlim[2] - xlim[1])*dtw.xy[1],
  #   dtw.ylim[1] * dtw.xy[2],
  #   Attribute$DTW.Reliability, adj=1, family='sans', font=4, cex=1.25
  # )
}


#' Title
#'
#' @param PID
#'
#' @return
#' @export
#'
#' @examples
plot.ndvi <- function(PID) {

  # Extract the parcel of interest.
  #Parcel    <- subset(Covariates, Parcel==PID)
  rspcl <- rs %>% filter(Parcel == PID)
  # Parcel    <- subset(Covariates2, Parcel==PID)
  # Attribute <- subset(Attributes, Parcel==PID)

  # We are only plotting one number per year here.  Get the number of
  # years to plot.

  n <- dim(rspcl)[1]

  # YLIM
  # Check the y-axis limits.  Extend them if necessary.
  ym <- max(rspcl$NDVI_SUR) + .01
  ymin <- min(rspcl$NDVI_SUR) - .01
  # ymin <- 0
  # ylim <- c(0, .6)

  # ylim <- c(ymin, ym)
  ylim <- c(ymin,ym)

  # if (max(Parcel$NDVI_SUR, na.rm=TRUE) > -1.5) { ylim <- c(ymin, ym) }
  #
  # # Set up a blank plot first.

  plot(xlim, ylim, xlab='', ylab='NDVI [dimensionless]', xlim=xlim, ylim=ylim, type='n', yaxs='i', axes=F)

  # Jazz it up with pretty axes and a frame.

  axis(side=1, at=seq(xlim[1], xlim[2]), labels=FALSE, tcl=-0.2)
  axis(side=1, at=pretty(xlim))
  axis(side=2, at=pretty(ylim), las=2)
  abline(h=pretty(ylim), col="lightgray")
  box()

  # Draw in the bars for each row (i.e., each year).

  for (i in 1:n) {

    # Draw in the bar for the year.  We need an x and a y vector to give the
    # corners of the bar that will be filled in with color.

    bar.x <- c(rep(rspcl$Year[i]-bar.space, 2), rep(rspcl$Year[i]+bar.space, 2))
    bar.y <- c(0, rspcl$NDVI_SUR[i], rspcl$NDVI_SUR[i], 0)

    polygon(bar.x, bar.y, col='green')
  }

  # If there is a baseline, add a horizontal line for the baseline.
  # This will allow the subsequent plotting to overlay the line.
  # Only do this if the data will be analyzed using Dunnett's method.


  # abline(h=Parcel$NDVI_SUR[1], lwd=1, col ='blue')

  #text(rmarg, Parcel$NDVI_SUR[1], 'Baseline', adj=0, xpd=NA)


}



#' Title
#'
#' @param PID
#'
#' @return
#' @export
#'
#' @examples
plot.ppt <- function(PID) {

  # Extract the parcel of interest.
  #Parcel    <- subset(Covariates, Parcel==PID)
  ppt <- rs %>% filter(Parcel == PID)
  # Parcel    <- subset(Covariates2, Parcel==PID)
  # Attribute <- subset(Attributes, Parcel==PID)

  # We are only plotting one number per year here.  Get the number of
  # years to plot.

  n <- dim(ppt)[1]

  # HARD-CODED NUMBER:
  # Check the y-axis limits.  Extend them if necessary.

  # ylims are defined in setup chunk
  ylim <- c(0,400)


  # Set up a blank plot first.

  plot(xlim, ylim, xlab='', ylab='PPT [mm]', xlim=xlim, ylim= ylim, type='n', yaxs='i', axes=F)

  # Jazz it up with pretty axes and a frame.

  axis(side=1, at=seq(xlim[1], xlim[2]), labels=FALSE, tcl=-0.2)
  axis(side=1, at=pretty(xlim))
  axis(side=2, at=pretty(ylim), las=2)
  abline(h=pretty(ylim), col="lightgray")
  box()

  # Draw in the bars for each row (i.e., each year).

  for (i in 1:n) {

    # Draw in the bar for the year.  We need an x and a y vector to give the
    # corners of the bar that will be filled in with color.

    bar.x <- c(rep(ppt$Year[i]-bar.space, 2), rep(ppt$Year[i]+bar.space, 2))
    bar.y <- c(0, ppt$PPT[i], ppt$PPT[i], 0)

    polygon(bar.x, bar.y, col='lightblue')
  }
  # abline(h=Parcel$PPT[1], lwd=1,col='blue')

  #text(rmarg, Parcel$PPT[1], 'Baseline', adj=0, xpd=NA)
}


# plot.perennial.cover()
#
# Function to create the perennial cover plot.

#' Title
#'
#' @param PID
#' @param transects
#'
#' @return
#' @export
#'
#' @examples
plot.perennial.cover <- function(PID, transects) {

  stderr <- function(x) { return(sqrt(var(x)/length(x))) }

  # Extract the parcel of interest.

  Transect <- subset(transects, Parcel==PID)
  # Attribute3 <- subset(Attributes3, Parcel==PID)

  # Calculate mean and standard error of the mean for each year.

  # Cover.mean <- aggregate(Transect$Cover, list(Year=Transect$Year), FUN=mean)
  # colnames(Cover.mean) <- c('Year', 'Mean')

  Cover.mean <- Transect %>% group_by(Year) %>% dplyr::summarise(Mean=mean(Cover))

  # Cover.stderr <- aggregate(Transect$Cover, list(Year=Transect$Year), FUN=stderr)
  # colnames(Cover.stderr) <- c('Year', 'SEM')

  Cover.stderr <- Transect  %>% group_by(Year) %>% dplyr::summarise(SEM=stderr(Cover))

  stats <- Cover.mean%>%left_join(Cover.stderr, by="Year") %>% arrange(Year)

  # stats <- merge(Cover.mean, Cover.stderr, by="Year") %>% arrange(Year)


  n <- dim(stats)[1]

  # Check the y-axis limits.  Extend them if necessary.
  this.max.cover <- max(stats$Mean, na.rm=TRUE)+15
  this.min.cover <- min(stats$Mean, na.rm=TRUE)

  ylim <- c(0, this.max.cover)
  # ylim <- c(0, 60)
  #ylim <- c(0, 104)

  #if (max(stats$Mean + stats$SEM + asterisk.offset, na.rm=TRUE) > 60) { ylim <- c(0, 104) }

  # Set up a blank plot first.

  plot(xlim, ylim, xlab='', ylab='Perennial Cover [%]', xlim=xlim, ylim=ylim, yaxs='i', type='n', axes=F)

  # add axes and a frame.

  axis(side=1, at=seq(xlim[1], xlim[2]), labels=FALSE, tcl=-0.2)
  axis(side=1, at=pretty(xlim))
  axis(side=2, at=pretty(ylim), las=2)
  abline(h=pretty(ylim), col="lightgray")
  box()

  # If there is a baseline, add a horizontal line for the baseline.
  # This will allow the subsequent plotting to overlay the line.
  # Only do this if the data will be analyzed using Dunnett's method.

  abline(h=stats$Mean[1], lwd=1,col='blue')

  # text(rmarg, stats$Mean[1], 'Baseline', adj=0, xpd=NA)


  # Draw in the bars for each row (i.e., each year).

  for (i in 1:n) {

    # Draw in the bar for the year.  We need an x and a y vector to give the
    # corners of the bar that will be filled in with color.

    bar.x <- c(rep(stats$Year[i]-bar.space, 2), rep(stats$Year[i]+bar.space, 2))
    bar.y <- c(0, stats$Mean[i], stats$Mean[i], 0)

    polygon(bar.x, bar.y, col='brown')
  }

  # Draw in the standard error bars for each row.

  for (i in 1:n) {

    # Draw in the 95% CI or 1.96 * standard error of the mean using the usual graphics.

    lines(c(stats$Year[i], stats$Year[i]), c(stats$Mean[i]-1.96*(stats$SEM[i]), stats$Mean[i]+1.96*(stats$SEM[i])))
    lines(c(stats$Year[i]-bar.space, stats$Year[i]+bar.space), rep(stats$Mean[i]-1.96*(stats$SEM[i]),2))
    lines(c(stats$Year[i]-bar.space, stats$Year[i]+bar.space), rep(stats$Mean[i]+1.96*(stats$SEM[i]),2))

  }

  # Now, rather than performing the one-way analysis of variance (weighted) followed
  # by Dunnett's method, we will simply perform a two-sample t-test with unequal
  # variances.  Note that the weighted analysis of variance is essentially
  # a generalization of this approach.

  ## remove this analyzable dependency to force in one sample tests
  #if (analyzable) {

  # We want to pick off the first year.  For safety's sake, we
  # sort the data to make sure they are in order, although
  # that seems to be a side effect of the code above.

  stats <- arrange(stats, Year)

  # Set up a container for the p-values.

  pvalues <- rep(NA, n)

  # Just roll through the other years one by one.  This could probably
  # be done more compactly.  On the other hand, it should be clear
  # what is happening here.

  #  TO DO:  What *would* be better would be cleaning
  # up this clunky method of getting the years.  It would be best
  # to have a list (vector) containing the years to be analyzed.

  # periodically the error
  # Error in t.test.default(data2, mu = mu.d1) : 'mu' must be a single number


  for (i in 2:n) {

    # data1 <- Transect$Cover[Transect$Year==stats$Year[1]]#baseline
    # data1 <- Transect$Cover[Transect$Year==1986]#baseline
    data1 <- Transect$Cover[Transect$Year < 1989]
    # data1 <- Transect$Cover[Transect$Year %in% c(1984,1985,1986,1987,1988)]

    mu.d1<-mean(data1)

    data2 <- Transect$Cover[Transect$Year==stats$Year[i]]#all other years in time series

    # per the greenbook update in 2017, I use the two sample t-test for parcels with greater than four transects and non-zero variance; and the one sample t-test with mu = mean of small sample or the live cover value reduced to perennial only from the wvcom variable.

    ifelse (length(data1) <= 4,#if parcel has less than five transects or was assigned a single wvcomm live cover variable as the baseline cover, conduct a one sample t-test on reduced live cover based on proportion of perennial grass and perennial total cover assigned to the parcel.

            fit <- t.test(data2, mu = mu.d1),
            fit <- t.test(data1,data2)# otherwise conduct the two sample t-test, defaulting to welch-satherwaite method to account for unequal variance.
    )

    pvalues[i] <- fit$p.value
  }

  # Add an asterisk according to whether the comparison with
  # baseline was significant.

  for (i in 1:n) {

    if (!is.na(pvalues[i]) & pvalues[i] < 0.05) {
      text(stats$Year[i], stats$Mean[i]+2.0*(stats$SEM[i])+ asterisk.offset, '*', adj=.6)
    }
  }

}



# plot.perennial.cover()
## Function to create the perennial cover plot.
#PID<-"BLK044"
#' Title
#'
#' @param PID
#' @param transects
#'
#' @return
#' @export
#'
#' @examples
plot.perennial.grass <- function(PID, transects) {

  stderr <- function(x) { return(sqrt(var(x)/length(x))) }
  # Extract the parcel of interest.

  grass.pcl <- subset(transects, Parcel==PID)
  # Attribute3 <- subset(Attributes3, Parcel==PID)

  # Calculate mean and standard error of the mean for each year.

  # rewrite old code using dplyr pipes. reads more logically

  #old way
  #Grass.mean <- aggregate(Transect$Grass, list(Year=Transect$Year), FUN=mean)
  #colnames(Grass.mean) <- c('Year', 'Mean')

  #new
  Grass.mean <- grass.pcl  %>% group_by(Year) %>% dplyr::summarise(Mean=mean(Grass))


  # Grass.stderr <- aggregate(Transect$Grass, list(Year=Transect$Year), FUN=stderr)
  # colnames(Grass.stderr) <- c('Year', 'SEM')

  Grass.stderr <- grass.pcl  %>% group_by(Year) %>% dplyr::summarise(SEM=stderr(Grass))


  stats <- Grass.mean%>%left_join(Grass.stderr, by="Year") %>% arrange(Year)


  # Get the number of years to plot.
  n <- dim(stats)[1]

  # this.max.cover <- max(stats$Mean, na.rm=TRUE)
  # this.min.cover <- min(stats$Mean, na.rm=TRUE)

  this.max.grass <- max(stats$Mean, na.rm=TRUE)+15
  this.min.grass <- min(stats$Mean, na.rm=TRUE)

  #ylim is finite

  # ylim <- c(0, 60)
  ylim <- c(0, this.max.grass)

  # Check the y-axis limits.  Extend them if necessary.

  # if (max(stats$Mean + stats$SEM + asterisk.offset, na.rm=TRUE) > 60) { ylim <- c(0, 104) }

  # Set up a blank plot first.

  plot(xlim, ylim, xlab='', ylab='Perennial Grass [%]', xlim=xlim, ylim=ylim, yaxs='i', type='n', axes=F)

  # add axes and a frame.

  axis(side=1, at=seq(xlim[1], xlim[2]), labels=FALSE, tcl=-0.2)
  axis(side=1, at=pretty(xlim))
  axis(side=2, at=pretty(ylim), las=2)
  abline(h=pretty(ylim), col="lightgray")
  box()

  # If there is a baseline, add a horizontal line for the baseline.
  # This will allow the subsequent plotting to overlay the line.



  abline(h=stats$Mean[1], lwd=1, col='blue')
  # text(rmarg, stats$Mean[1], 'Baseline', adj=0, xpd=NA)


  # Draw in the bars for each row (i.e., each year).

  for (i in 1:n) {

    # Draw in the bar for the year.  We need an x and a y vector to give the
    # corners of the bar that will be filled in with color.

    bar.x <- c(rep(stats$Year[i]-bar.space, 2), rep(stats$Year[i]+bar.space, 2))
    bar.y <- c(0, stats$Mean[i], stats$Mean[i], 0)

    polygon(bar.x, bar.y, col='lightgreen')
  }

  # Draw in the standard error bars for each row.

  for (i in 1:n) {

    # Draw in the 2 x standard error of the mean using the usual graphics.

    lines(c(stats$Year[i], stats$Year[i]), c(stats$Mean[i]-1.96*(stats$SEM[i]), stats$Mean[i]+ 1.96*(stats$SEM[i])))
    lines(c(stats$Year[i]-bar.space, stats$Year[i]+bar.space), rep(stats$Mean[i]-1.96*(stats$SEM[i]),2))
    lines(c(stats$Year[i]-bar.space, stats$Year[i]+bar.space), rep(stats$Mean[i]+1.96*(stats$SEM[i]),2))

  }

  # Now, rather than performing the one-way analysis of variance (weighted) followed
  # by Dunnett's method, we will simply perform a two-sample t-test with unequal
  # variances.  Note that the weighted analysis of variance is essentially
  # a generalization of this approach.

  # if (analyzable) {

  # We want to pick off the first year.  For safety's sake, we
  # sort the data to make sure they are in order, although
  # that seems to be a side effect of the code above.

  stats <- arrange(stats, Year)

  # Set up a container for the p-values.

  pvalues <- rep(NA, n)

  # Just roll through the other years one by one.  This could probably
  # be done more compactly.  On the other hand, it should be clear
  # what is happening here.

  # TO DO:  What *would* be better would be cleaning
  # up this clunky method of getting the years.  It would be best
  # to have a list (vector) containing the years to be analyzed.

  # blyears<-c(1984,1985,1986,1987,1988)
  for (i in 2:n) {#start at 2 because 1 is the baseline year and this for loop is only for each comparison to baseline
    #Transect$Grass[Transect$Year==stats$Year[1]]
    #str(stats)
    #length(data1)
    # data1 <- Transect$Grass[Transect$Year==stats$Year[1]]#baseline
    data1 <- grass.pcl$Grass[grass.pcl$Year < 1989]
    # data1 <- Transect$Grass[Transect$Year %in% c(1984,1985,1986,1987,1988)]#baseline

    mu.d1<-mean(data1)



    # could have a covariate indicating  baseline year and flags for comparisons, ordinal perhaps
    data2 <- grass.pcl$Grass[grass.pcl$Year==stats$Year[i]]
    #mu <- data1
    # str(mu)
    #ifelse(length(data1) == 0), mu= 0,

    ifelse (length(data1) <= 4,#if parcel has single transect or was assigned the wvcomm variable as the baseline cover, conduct a one sample t-test. this should include the value of zero for grass where no grass detected during baseline.

            fit <- t.test(data2, mu = mu.d1),

            fit <- t.test(data1,data2)# otherwise conduct the two sample t-test, defaulting to welch-satherwaite method to account for unequal variance.
    )


    # fit <- t.test(data1, data2)

    pvalues[i] <- fit$p.value
  }
  # kable(pvalues)
  # Add an asterisk according to whether the comparison with
  # baseline was significant.

  for (i in 1:n) {

    if (!is.na(pvalues[i]) & pvalues[i] < 0.05) {
      text(stats$Year[i], stats$Mean[i]+2*(stats$SEM[i])+ asterisk.offset, '*', adj=.5)
    }
  }
  # }
}




# # five_row_timeseries <- function(attributes_pfix, transects, dtw_pfix, rs_pfix, cYear){
#
#   stderr <- function(x) { return(sqrt(var(x)/length(x))) }
#
#
#   # Set global configurations.
#
#   r.squared.digits <- 2  ### Round the r-squared values to this many digits.
#   p.value.digits   <- 4  ### Round the p-values to this many digits
#   b.digits         <- 4  ### Round the estimates to this many digits
#
#
#
#   # Configure global plot tuning parameters.
#
#   bar.space <- 0.25        ### The space between each bar on the graphs.
#
#   # can define year here for x-axis if doing one off pdf export
#   xlim <- c(1985, 2020)   ### The x-axis limits for the graphing
#   #xlim <- c(1985, cYear)   ### The x-axis limits for the graphing effort.
#   ylim <- c(0, 62.4)       ### The y-axis limits for percentage cover.
#   ylim.ndvi<-c(.1,.8)
#   dtw.max <- 5             ### Maximum y-axis limits for the DTW measurements.
#   dtw.split <- 6           ### Where to switch the y-axis for the DTW measurements.
#   dtw.xy <- c(.95, .90)    ### DTW plot annotation location.
#   asterisk.offset <- 4     ### How much to space the asterisks.
#   rmarg <- cYear + 1.5     ### Tune stuff in the right margin.
#   show.caption <- TRUE     ### Print a figure caption or not?
#
# AttributesPID <- attributes_pfix %>% filter(reinv == "r", Parcel %in% c("BLK094","BLK099"))
#
#   # filter(!Parcel %in% c('BGP013','BLK006',"BGP204", "BGP205", "BLK008", "FSL179", "IND086", "LAW076", "LAW110","MAN038", "PLC113", "PLC220", "TIN006", "UNW074"))
#
# PIDs <- unique(AttributesPID$Parcel)
# # all.pid <- PIDs
#
# # layout = "l-page",
# # FILEpdf <- paste0(dir, '/output/TimeSeries2018.all.pdf')
# FILEpdf <- "output/time_series_all_f2020e.pdf"
# # library(plyr)
# fig.num <- 1
#
# pdf(FILEpdf)
# # png(FILEpng)
# par(mfrow=c(5,1), oma=c(5,0,5,0), plt=c(.1,.85,.1,.85))
#
# for (PID in PIDs) {
#   # call functions
#   plot.perennial.cover(PID, transects)
#   plot.perennial.grass(PID, transects)
#   plot.dtw(PID, dtw_pfix)
#   plot.ndvi(PID, rs_pfix)
#   plot.ppt(PID, rs_pfix)
#
#   # caption variables
#   # Parcel <- parcels %>% filter(Parcel==PID)
#
#   Attribute3 <- attributes_pfix %>% filter(Parcel==PID)
#   Transect.n <- transects %>% filter(Parcel==PID,Year==cYear)
#   n.tran <-  Transect.n %>% group_by(Parcel) %>% dplyr::summarise(count = n())
#
#   Descriptor <- paste(PID,'(W/C): ',Attribute3$Type,'| Type: ', Attribute3$GB_TYPE,'|', Attribute3$Holland, sep=' ')
#   ESD <- paste(Attribute3$taxorder, Attribute3$compname,  '| ESD: ',Attribute3$Ecologic_3, sep=' ')
#   geom <- paste('Geomorphic:',Attribute3$geomdesc)
#   # last.year <- max(Parcel$Year, na.rm=TRUE)
#   test.type <- Attribute3$test_type
#   Caption <- paste('Figure ', fig.num, ': ', test.type,': Baseline (',Attribute3$bl.origin,') vs. reinventory (* p < 0.05).\n Baseline sample size (n = ',Attribute3$n86,'). Current year sample size (n = ',n.tran$count,').', ' Error bars = 95% CI.', sep='')
#   mtext(side=3, outer=TRUE, line=0, geom)
#   mtext(side=3, outer=TRUE, line=3, Descriptor)
#   mtext(side=3, outer=TRUE, line=1.5, ESD)
#   mtext(side=1, outer=TRUE, line=3, adj=0.15, family='serif', Caption)
#   # update fig.num for next plot
#   fig.num <- fig.num + 1
#   }
# dev.off()
# }


#' Title
#'
#' @param transects
#' @param attributes_reinv
#'
#' @return
#' @export
#'
#' @examples
nest_transects <- function(transects, attributes_reinv){

  byparyear <- transects %>% filter(Parcel %in% attributes_reinv$Parcel) %>%
    group_by(Parcel,Year) %>%
    nest() %>%
    mutate(n = map_dbl(data,nrow))

  gb <- byparyear %>% filter(Year > 1990)
  bl <- byparyear %>% filter(Year < 1990)
  parcel_year_nested_transects <- gb %>% left_join(bl, by = 'Parcel')

  return(parcel_year_nested_transects)
}

#' Title
#'
#' @param data.x
#' @param data.y
#'
#' @return
#' @export
#'
#' @examples
t2samp <- function(data.x, data.y) {
  failproof.t <- purrr::possibly(t.test, NA_real_)
  failproof.t(data.x$Cover,data.y$Cover, conf.level = .95)
}

#' Title
#'
#' @param data.x
#' @param data.y
#'
#' @return
#' @export
#'
#' @examples
t1samp <- function(data.x, data.y) {
  failproof.t <- purrr::possibly(t.test, NA_real_)
  failproof.t(data.x$Cover,mu = mean(data.y$Cover), conf.level = .95)

}

#' Title
#'
#' @param parcel_year_meta_2samp
#'
#' @return
#' @export
#'
#' @examples
two_sample_ttest <- function(parcel_year_meta_2samp){
parcel_year_meta_2samp %>% mutate(model = map2(data.x, data.y, t2samp)) %>%
  mutate(glance = map(model, broom::glance)) %>%
  unnest(glance) %>% mutate(significance = ifelse(p.value < 0.05, ifelse(statistic > 0  ,'ns','significant'),'ns'))
}

#' Title
#'
#' @param parcel_year_meta_1samp
#'
#' @return
#' @export
#'
#' @examples
one_sample_ttest <- function(parcel_year_meta_1samp){
  parcel_year_meta_1samp %>% mutate(model = map2(data.x, data.y, t1samp)) %>%
    mutate(glance = map(model, broom::glance)) %>%
    unnest(glance) %>%
    # hoist(model,"null.value") %>%
    mutate(significance = ifelse(p.value < 0.05,
                                 ifelse(statistic > 0 ,'ns','significant'),
                                 'ns')
           )
}

#' Title
#'
#' @param data
#' @param cYear
#'
#' @return
#' @export
#'
#' @examples
plot_1samptest_timeseries <- function(data,cYear,parcel.select){
  data <- data %>% filter(Parcel %in% parcel.select)
  plot <- data %>% ggplot(aes(x=Year.x))+
    ggtitle(paste("Perennial Cover (1991-",cYear,") Compared to Baseline (1984-1987).
 One-Sample t-test (mu = mean of baseline transects for n < 5, ns p > 0.05, significant p < 0.05"))+
  # ns (not significant, p > 0.05), significant (p < 0.05)")
  # +
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high,color=significance,width=0.2))+
  geom_line(aes(y=estimate))+
  # geom_line(aes(y=baseline, color='Baseline'))+#baseline year
  scale_color_manual(values = c("blue", "red"))+
  ylim(0,100)+
  ylab("Perennial Cover (%)")+
  facet_wrap(~Parcel, ncol = 1)+
    theme(legend.position="top")
  # ggsave("plot_1samp.png", plot, width = 7, height = 7)
  # return("plot_1samp.png")
  return(plot)

}


#' Title
#'
#' @param data
#' @param cYear
#'
#' @return
#' @export
#'
#' @examples
plot_2samptest_timeseries <- function(data,cYear,parcel.select){
  data <- data %>% filter(Parcel %in% parcel.select)
  plot <- data %>% ggplot(aes(x=Year.x))+
  ggtitle(paste("Perennial Cover Time Series (1991-",cYear,") Relative to Baseline (1984-1987).
  Welch Two Sample t-test (ns p > 0.05, significant p < 0.05)"))+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high,color=significance,width=0.2))+
  geom_line(aes(y=estimate1))+#reinventory year
  scale_color_manual(values = c("green","orange", "blue", "red"))+
    # scale_color_npg()+
  geom_line(aes(y=estimate, color='Deviation from Baseline\n (relative to zero)'))+#baseline year
  geom_line(aes(y=estimate2, color='Baseline'))+#baseline year
  # ylim(0,100)+
  ylab("Perennial Cover (%)")+
  facet_wrap(~Parcel,ncol = 1)+
    theme(legend.position="top")
  # ggsave("plot_2samp.png", plot, width = 7, height = 7)
  # return("plot_2samp.png")
  return(plot)

}

#' join_summaries
#'
#' @param parcels_deltas
#' @param attributes_pfix
#' @param parcel_year_meta_combined_results
#' @param cYear
#'
#' @return
#' @export
#'
#' @examples
join_summaries <- function(parcels_deltas,attributes_pfix, parcel_year_meta_combined_results, cYear){

deltas <- parcels_deltas %>%
  filter(Year == cYear) %>%
  select(Parcel, TLC, Cover, Cover.Delta, Grass, pGrass, Grass.Delta, Shrub, pShrub, Shrub.Delta)%>%
  mutate(across(Cover:Shrub.Delta, round, 1))

test <- parcel_year_meta_combined_results %>%
  filter(Year.x == cYear)

par.delta.test.att <- deltas %>%
  left_join(test, by = 'Parcel') %>%
  left_join(attributes_pfix, by = 'Parcel')

# datatable(par.delta.test.att)
return(par.delta.test.att)

}

parcel_data_table <- function(deltas_ttest_att,cYear){
  table <- deltas_ttest_att %>% mutate(p.value = round(p.value,3)) %>%
    filter(!Parcel %in% c("FSL044")) %>%
    select(Parcel,GB_TYPE,Holland,wellfield,Type, Cover.Delta,p.value,
           significance,method,Grass.Delta, Shrub.Delta,
           pGrass,pShrub,Cover,Grass,Shrub) %>%
    datatable(filter = 'top',
              options = list(
                dom = 'Blfrtip',
                buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                scrollX = TRUE,
                fixedColumns = list(leftColumns = 2, rightColumns = 0),
                pageLength = 5,
                autoWidth = TRUE,
                colReorder = TRUE)
              # ,
              # caption = paste("Baseline vs",cYear,"statistical significance summary."

              )


  # %>% htmlwidgets::saveWidget('parcel-summary.html')

  # return("parcel-summary.html")
  return(table)
}


panel_map<- function(cYear,parcels_shp_ttest, wf, or,streams,canals,laa,lakes, monit.sites){

  # write function to handle custom plot with input as string e.g. 'Laws'
  limit <- parcels_shp_ttest %>% filter(grepl(wf,wellfield))

  tpc.below <- limit %>% filter(significance == 'significant')
  # the perennial grass currently doesn't have the sig tests,
  # so we specify this manually on the attribute table for now.
  pgr.below <- limit %>% filter(pgr20 == 1)

  tmap_mode("plot")

  #-----------------------------------------
  tmgrass <-

    tm_shape(limit, group = 'Wellfield - Parcels') +
    tm_polygons(col =c("Grass"), breaks = c(0,5,10,15,20,25,30,35,40,50,60,Inf), palette = "Greens",title.col = "PCL_merged",  id = "PCL_merged",popup.vars = c("GB_TYPE","Ecologic_3","COMM_NAME","Grass.Delta","Cover.Delta", "NDVI.delta","NDVI.Baseline","Type"), group = "Wellfield - Parcels")+

    tm_shape(pgr.below, group = 'Wellfield - Parcels') +
    tm_borders(col = 'red',lwd = 2)+
    tm_text("PCL", size = .5,  col = "white",shadow=TRUE,remove.overlap=FALSE, group = 'Labels', auto.placement = .2, bg.color = 'darkgreen')

  #-----------------------------------------
  tmgrassd <- tm_shape(limit, group = 'Wellfield - Parcels') +

    tm_polygons(col =c("Grass.Delta"), breaks = c(-40,-30,-20,-10,-5,5,10,20,30,40,Inf),palette = "RdYlGn",title.col = "PCL_merged",  id = "PCL_merged",popup.vars = c("GB_TYPE","Ecologic_3","COMM_NAME","Grass.Delta","Cover.Delta", "NDVI.delta","NDVI.Baseline","Type"), group = "Wellfield - Parcels")+

    tm_shape(pgr.below, group = 'Wellfield - Parcels') +
    tm_borders(col = 'red',lwd = 1)+
    tm_shape(canals, group = 'Canals') +
    tm_lines(col = "blue", scale = .6, group = 'Canals')+
    tm_shape(streams, group = 'Streams') +
    tm_lines(col = "blue", scale = 1, group = 'Streams')+
    tm_shape(monit.sites, group = 'On/Off Monitoring Sites') +
    tm_text("SITE",  col = "white", size=.5,remove.overlap=TRUE,shadow=TRUE,group = 'Labels',auto.placement = .1,bg.color = 'blue') +
    tm_symbols(col = "blue", scale = .05, title.col = "SITE",  id = "SITE",popup.vars = c("SITE","TYPE"),group = 'On/Off Monitoring Sites')+
    tm_shape(or, group = 'River') +
    tm_lines(col = "blue", scale = 1, group = 'River')+
    tm_shape(laa, group = 'LAA') +
    tm_lines(col = "blue", scale = 1, group = 'LAA')+
    tm_shape(lakes, group = 'Lakes') +
    tm_polygons(col = "blue", scale = 1, group = 'Lakes')

  #-----------------------------------------

  tmcov <- tm_shape(limit, group = 'Wellfield - Parcels') +

    tm_polygons(col =c("Cover"), breaks = c(0,5,10,15,20,25,30,35,40,50,60,Inf),palette = "Greens",title.col = "PCL_merged",  id = "PCL_merged",popup.vars = c("GB_TYPE","Ecologic_3","COMM_NAME","Grass.Delta","Cover.Delta", "NDVI.delta","NDVI.Baseline","Type"), group = "Wellfield - Parcels")+
    tm_shape(tpc.below, group = 'Wellfield - Parcels') +
    tm_borders(col = 'red',lwd = 2)+
    tm_text("PCL",  size = .5,col = "white",shadow=TRUE,remove.overlap=FALSE, group = 'Labels', auto.placement = .2, bg.color = 'darkgreen')
  #-----------------------------------------
  tmcovd <- tm_shape(limit, group = 'Wellfield - Parcels') +
    tm_polygons(col =c("Cover.Delta"), breaks = c(-40,-30,-20,-10,-5,5,10,20,30,40,Inf),palette = "RdYlGn",title.col = "PCL_merged",  id = "PCL_merged",popup.vars = c("GB_TYPE","Ecologic_3","COMM_NAME","Grass.Delta","Cover.Delta", "NDVI.delta","NDVI.Baseline","Type"), group = "Wellfield - Parcels")+

    tm_shape(tpc.below, group = 'Wellfield - Parcels') +
    tm_borders(col = 'red')+
    tm_shape(canals, group = 'Canals') +
    tm_lines(col = "blue", scale = .6, group = 'Canals')+
    tm_shape(streams, group = 'Streams') +
    tm_lines(col = "blue", scale = .7, group = 'Streams')+
    tm_shape(monit.sites, group = 'On/Off Monitoring Sites') +
    tm_text("SITE",  col = "white", size=.5,remove.overlap=TRUE,shadow=TRUE,group = 'Labels',auto.placement = .1,bg.color = 'blue') +
    tm_symbols(col = "blue", scale = .05, title.col = "SITE",  id = "SITE",popup.vars = c("SITE","TYPE"),group = 'On/Off Monitoring Sites')+
    tm_shape(or, group = 'River') +
    tm_lines(col = "blue", scale = 1, group = 'River')+

    tm_shape(laa, group = 'LAA') +
    tm_lines(col = "blue", scale = 1, group = 'LAA')+

    tm_shape(lakes, group = 'Lakes') +
    tm_polygons(col = "blue", scale = 1, group = 'Lakes')

map <-tmap_arrange(tmgrass, tmgrassd,tmcov,tmcovd,ncol=2)

tmap_save(map,paste0('output/',cYear,'_',wf,'map.png'))

  return(paste0('output/',cYear,'_',wf,'map.png'))


}


```


## `workflowr`
Once the targets are defined in the `_targets.R` script, running tar_make() stores the targets in the `_targets` subdirectory to the root of the project, where the .Rproj is located. Now any `.Rmd` anywhere within the project directory can access these targets made from the dependency-aware pipeline. The default `workflowr` project directory encourages `.Rmd` files to be located in the `analysis` directory and these `analysis/file.Rmd` can access the hard-earned data products from the pipeline, and `workflowr::wflow_build()` will render the `.Rmd` to an html website in the `docs` directory that can be version controlled on github and hosted on github-pages. workflowr research websites include seven reproducibility checks including that the output was derived from a 'committed' file to version control, the R environment was empty, seed set, session information recorded, no cache, file paths are relative, and which repository version relates to the website.
```{r wflow-steps,eval=FALSE}
wflow_publish(c("analysis/index.Rmd", "analysis/about.Rmd", "analysis/license.Rmd","analysis/index.Rmd","_targets.R","code/R/functions.R"),
              "Added maps of sig veg change to reports rmd, update map function, functions to enumerate parcels/transects per year.")

wflow_publish(c("analysis/report.Rmd"),
              "Added maps of sig veg change to reports rmd, update map function.")

wflow_publish(c("analysis/report.Rmd"),
              "update Rmd.")


# wflow_git_commit("analysis/report.Rmd")

git push -u origin master
```


```{r load-targets}
tar_load(n_parcels_all_years)


tar_load(icwd_ladwp_bind)
tar_load(lpt_updated_master)
tar_load(transects)
tar_load(parcels_shp)
tar_load(parcels_deltas)#parcel-year-deltas
tar_load(parcel_year_meta_2samp_results)
tar_load(parcel_year_meta_1samp_results)
tar_load(parcel_year_meta_combined_results)
tar_load(deltas_ttest_att)

tar_load(wellcont_means_rarefied)
tar_load(plot_wellcontrol)

tar_load(plot_1sample_timeseries)
tar_load(plot_2sample_timeseries)
tar_load(parcel_datatable)

tar_load(attributes_reinv)

tar_load(panel_map_lw)
tar_load(panel_map_bp)
tar_load(panel_map_ta)
tar_load(panel_map_ts)
tar_load(panel_map_io)
tar_load(panel_map_ss)
tar_load(panel_map_bg)
# tar_load(panel_map_lp)
# tar_load(monsites_shp)
```

# Results {.tabset}

```{r parcel-attributes,include=FALSE,eval=FALSE}
# Parcel Attributes
attributes_reinv%>%
  datatable(extensions = c('Buttons','FixedColumns'),
            filter = c("top"),
            options = list(
              dom = 'Bfrtip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
              scrollX = TRUE,
              fixedColumns = list(leftColumns = 2, rightColumns = 0),
              pageLength = 5, 
              autoWidth = TRUE)
            )
```

```{r cyr-tran-species,include=FALSE, eval=FALSE}
# Current year data
icwd_ladwp_bind %>% filter(Cover > 0)%>%
  datatable(extensions = c('Buttons','FixedColumns'),
            filter = c("top"),
            options = list(
              dom = 'Bfrtip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
              scrollX = TRUE,
              fixedColumns = list(leftColumns = 2, rightColumns = 0),
              pageLength = 5, 
              autoWidth = TRUE)
            )
```

```{r tran-species,include=FALSE, eval=FALSE}
# Total combined data
lpt_updated_master %>% filter(Cover > 0)%>% 
  datatable(extensions = c('Buttons','FixedColumns'),
            filter = c("top"),
            options = list(
              dom = 'Bfrtip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
              scrollX = TRUE,
              fixedColumns = list(leftColumns = 2, rightColumns = 0),
              pageLength = 5, 
              autoWidth = TRUE)
            )

```

```{r tran-ftype,include=FALSE, eval=FALSE}
# Aggregated to transect cover type
transects%>% 
  datatable(extensions = c('Buttons','FixedColumns'),
            filter = c("top"),
            options = list(
              dom = 'Bfrtip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
              scrollX = TRUE,
              fixedColumns = list(leftColumns = 3, rightColumns = 0),
              pageLength = 5, 
              autoWidth = TRUE)
            )
```


## Wellfield Control Comparison{data-short-title="Wellfield-Control"}


For an overview of the pumping effect on GDEs in Owens Valley, parcels were classified as either belonging to a wellfield group or control group, based on drawdown from 1987 and 1993, the period of maximum pumping rate. ^[Parcels were assigned to the wellfield group if (1) kriged depth-to-water (DTW) estimates exceeded 1-m water-table drawdown during 1987-1993 or (2) they were located at sites corresponding to modeled drawdown contours greater than 10 ft. Parcels were assigned to the control group if (1) kriged DTW estimates were less than 1 m and (2) they were located at sites corresponding to modeled drawdown contours less than 10 ft. If the kriged DTW estimates were not reliable owing an inadequate test-well network near the vegetation parcel, then the groundwater-flow model estimate of the 10-ft drawdown contour was used as the sole criteria to designate parcels as either wellfield or control. An exception to the above criteria was applied to parcels associated with drawdown contours greater than 10-ft yet located near a surface water source (specifically, a canal, sewer pond, creek, river, or a ground water seepage source) that would lessen local drawdown effects — these parcels were classified as control.]

Here the subset of wellfield and control parcels that have been sampled in every year 1992-`r cYear` are considered to remove any trend potentially associated with group sample sizes that may have fluctuated over the years. Wellfield and control group averages are plotted for comparison over time and linear trends are reported for total cover and for the perennial herbaceous component and woody shrub component of total cover separately.   

```{r plot-wellcontrol}
plot_wellcontrol
```


 
## Parcel Cover

In the `r cYear` growing season, ICWD and LADWP monitored `r n_parcels_sampled` vegetation parcels with approximately `r n_transects_sampled` vegetation transects using the line-point-intercept method described in the Green Book. 

parcel-year-cover

```{r parcel-deltas-table}
parcels_deltas %>% 
  select(Parcel, Year,Cover, Cover.Delta, Grass, Grass.Delta, Shrub, Shrub.Delta) %>% 
  mutate(across(Cover:Shrub.Delta, round, 1)) %>% 
  datatable(extensions = c('Buttons','FixedColumns'),
            filter = c("top"),
            options = list(
              dom = 'Blfrtip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
              scrollX = TRUE,
              fixedColumns = list(leftColumns = 2, rightColumns = 0),
              pageLength = 5, 
              autoWidth = TRUE)
            )
# %>% formatRound(c('july','oct'),2)
# deltas
```

## Stats
The baseline perennial vegetation cover statistically compared to `r cYear` vegetation cover using either Welch Two Sample t-test or One Sample t-test depending on baseline sample size following Box I.C.1.a.ii.

```{r parcel-yr-ttest-cyear}
parcel_year_meta_combined_results %>% 
  filter(Year.x == cYear) %>% 
  select(Parcel,significance,  estimate, estimate1, estimate2, method,n.x, n.y, statistic, p.value) %>%  
  mutate(across(estimate:estimate2, round, 0)) %>%
  mutate(across(statistic:p.value, round, 3)) %>% 
  datatable(extensions = c('Buttons','FixedColumns'),
            filter = c("top"),
            options = list(
              dom = 'Blfrtip',
              buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
              scrollX = TRUE,
              fixedColumns = list(leftColumns = 2, rightColumns = 0),
              pageLength = 5, 
              autoWidth = TRUE)
            )


# ,filter = c("top"),options = list(
  # pageLength = 5, autoWidth = TRUE)) 


# est, est1, est2, stat, pval, par, clow, chigh, method, alt, sig
```

## Summary Table
Distillation of the effect size of parcel vegetation change (Cover.Delta, Grass.Delta, Shrub.Delta) from baseline to `r cYear`, including the `r cYear` proportion of grass (pGrass), shrub (pShrub), parcel average perennial total cover (Cover), and the functional types Grass and Shrub.

```{r parcel-delta-sig-table}
# tar_read(
  parcel_datatable
  
```

# Maps{.tabset}

## Laws
```{r}
knitr::include_graphics(here(panel_map_lw))
```

## Big Pine
```{r}
# library(knitr)
knitr::include_graphics(here(panel_map_bp))
```

## Taboose-Aberdeen
```{r}
knitr::include_graphics(here(panel_map_ta))
```

## Thibaut-Sawmill
```{r}
knitr::include_graphics(here(panel_map_ts))
```

## Symmes-Shepherd
```{r}
knitr::include_graphics(here(panel_map_ss))
```

## Bairs-George
```{r}
knitr::include_graphics(here(panel_map_bg))
```


```{r 2sample-graph,include=FALSE,eval=FALSE}
# Graph two-sample ttest, These graphs could be split out by wellfield
plot_2sample_timeseries
```

```{r 1sample-graph,include=FALSE,eval=FALSE}
# Graph one-sample ttest
plot_1sample_timeseries
```

# Discussion

Section I.C of the Green Book describes the measurable, attributable, and significance three-step evaluation the Technical Group will follow on a case by case basis to determine whether *decreases and/or changes in the vegetation or other significant effects on the environment have occurred or are occurring in a given management area and to ascertain whether a change is significant and whether mitigation is necessary.* The Green Book prescribes, *To determine if a significant effect has occurred or is occurring, the Technical Group first shall evaluate the measurability of the effect* (Green Book Section I.C.1.a); *if the effect is measurable, the cause shall be evaluated* (Green Book Section I.C.1.b); *if the cause of the effect is attributable to LADWP water management, the significance of the effect will then be assessed* (Green Book Section I.C.1.d). 

The list of parcels exhibiting measurable changes identified in this report meet the criteria for the Technical Group to evaluate the cause(s) of the apparent changes from baseline vegetation goals.

Section I.C.1.b. of the Green Book, 'Determining Attributability', describes,

>"Once it has been determined that there has been a measurable vegetation decrease or change, it must be determined whether the impact is attributable to groundwater pumping or to changes in surface water management practices.  A determination of whether the impact is attributable to groundwater pumping or changes in surface water management practices will be based on evaluation and consideration of relevant factors, which may include:

>i. Recent and historic water table changes and response to pumping as measured at the monitoring site(s) closest to the affected area.

>ii. Comparison of soil water, depth to water, and degree of vegetation decrease or change at the affected area and at the control site(s) determined to have similar soil type and vegetation composition and cover.

>iii. Comparison of water table depths in the affected area with water table depths in the general region with soils, vegetation cover, and vegetation composition comparable to the affected site. New shallow piezometers may be installed and monitored, if necessary, to obtain relevant water table data.

>iv. Rainfall differences that may exist between the control site(s) and the affected area.

>v. Evaluation of the extent to which other factors unrelated to the effects of groundwater pumping may have contributed to the vegetation change or decrease. Such factors include drought, wet/dry climatic cycles, flooding, fungal blight, range management practices, wildfire, and off road vehicles.

>vi. Change in soil water within the root zone caused by a pumping induced change in the water table.

>vii. Review of surface water operations to determine if changes from past practices contributed to vegetation changes.

>viii. A decrease in flow from a spring or flowing well.

>If a decrease in flow from a spring or flowing well occurs, the Technical Group shall determine whether the decrease corresponds to changes in groundwater pumping and runoff. If, on the basis of qualitatively evaluating the data, it appears that the decreased flow corresponds with increased pumping and decreased runoff, the Technical Group shall conduct a quantitative analysis of the data, using one or both of the methods described below, or any other method developed by the Technical Group:

>+ The Technical Group shall perform a regression analysis of the relevant groundwater level, spring flow, runoff/recharge, and pumping data associated with the site (an example of applying this technique is found in the Technical Group’s analysis of the water flow decrease at Reinhackel Spring).

>+ The Technical Group shall use the groundwater model of the area in question as a supplement to the regression analysis, or as a substitute for the regression analysis if the data are inadequate to develop a regression model. The model would be applied by evaluating groundwater level and spring flow changes in the area under the relevant runoff/recharge conditions that existed under pumping and nonpumping scenarios. For example, the runoff/recharge conditions that existed during the period that the suspected impact occurred would be quantified and entered into the model. The pumping that occurred at that time would also be entered. Results of this run would be compared to a run with the identical runoff/recharge conditions and no pumping. Evaluation of the results would include an analysis of the difference in water levels and/or spring flow in the area to determine if the change that is calculated by the model is sufficient to conclude a pumping related impact, given the assumptions and limitations of the model."

